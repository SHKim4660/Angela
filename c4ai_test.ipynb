{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install 'transformers>=4.39.1'\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"CohereForAI/c4ai-command-r-v01\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# Format message with the command-r chat template\n",
    "messages = [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]\n",
    "input_ids = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "## <BOS_TOKEN><|START_OF_TURN_TOKEN|><|USER_TOKEN|>Hello, how are you?<|END_OF_TURN_TOKEN|><|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    temperature=0.3,\n",
    "    )\n",
    "\n",
    "gen_text = tokenizer.decode(gen_tokens[0])\n",
    "print(gen_text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
